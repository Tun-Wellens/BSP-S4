{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/datasets/load.py:1461: FutureWarning: The repository for google/fleurs contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/google/fleurs\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "100%|██████████| 934/934 [00:03<00:00, 240.04it/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import whisper\n",
    "import random\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\n",
    "from transformers import pipeline\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "\n",
    "\n",
    "from transformers.models.whisper.english_normalizer import BasicTextNormalizer\n",
    "import evaluate\n",
    "\n",
    "normalizer = BasicTextNormalizer()\n",
    "wer_metric = evaluate.load(\"wer\")\n",
    "\n",
    "def normalize_text(text: str) -> str:\n",
    "    \"\"\"Normalize text using Whisper's basic text normalizer.\"\"\"\n",
    "    return normalizer(text.strip())\n",
    "\n",
    "def compute_wer(reference: str, prediction: str) -> float:\n",
    "    \"\"\"Compute WER between two strings after normalization.\"\"\"\n",
    "    norm_ref = normalize_text(reference)\n",
    "    norm_pred = normalize_text(prediction)\n",
    "    return wer_metric.compute(references=[norm_ref], predictions=[norm_pred])\n",
    "\n",
    "# Load the dataset\n",
    "dataset = load_dataset(\"google/fleurs\", \"lb_lu\")\n",
    "samples = dataset[\"test\"]\n",
    "\n",
    "prepared_samples = []\n",
    "\n",
    "import tempfile\n",
    "import soundfile as sf\n",
    "import torch\n",
    "import torchaudio\n",
    "from tqdm import tqdm\n",
    "\n",
    "for sample in tqdm(samples):\n",
    "    audio_array = sample[\"audio\"][\"array\"]\n",
    "    sample_rate = sample[\"audio\"][\"sampling_rate\"]\n",
    "    reference = sample[\"transcription\"].strip()\n",
    "\n",
    "    # Resample if necessary\n",
    "    if sample_rate != 16000:\n",
    "        audio_array = torchaudio.functional.resample(\n",
    "            torch.tensor(audio_array), orig_freq=sample_rate, new_freq=16000\n",
    "        ).numpy()\n",
    "\n",
    "    # Save to temp file\n",
    "    tmp_file = tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False)\n",
    "    sf.write(tmp_file.name, audio_array, 16000)\n",
    "\n",
    "    prepared_samples.append({\n",
    "        \"path\": tmp_file.name,\n",
    "        \"reference\": reference\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Load the Whisper model\\nmodel = whisper.load_model(\"medium\")\\n\\nrefs_preds = []\\nwers = []\\n\\nfor sample in tqdm(prepared_samples):\\n    # Transcribe the audio\\n    result = model.transcribe(sample[\"path\"], language=\"lb\", task=\"transcribe\")\\n    prediction = result[\"text\"].strip()\\n\\n    # Compute WER\\n    error = compute_wer(sample[\"reference\"], prediction)\\n    wers.append(error)\\n    refs_preds.append((sample[\"reference\"], prediction, error))\\n\\n# calculate average WER and print results\\naverage_wer = sum(wers) / len(wers)\\nprint(f\"Average WER: {average_wer:.2%}\")\\n\\n# show a few random samples\\n\\nfor ref, pred, err in random.sample(refs_preds, min(5, len(refs_preds))):\\n    print(f\"Reference: {ref}\")\\n    print(f\"Predicted: {pred}\")\\n    print(f\"WER: {err:.2%}\\n\")'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# Load the Whisper model\n",
    "model = whisper.load_model(\"medium\")\n",
    "\n",
    "refs_preds = []\n",
    "wers = []\n",
    "\n",
    "for sample in tqdm(prepared_samples):\n",
    "    # Transcribe the audio\n",
    "    result = model.transcribe(sample[\"path\"], language=\"lb\", task=\"transcribe\")\n",
    "    prediction = result[\"text\"].strip()\n",
    "\n",
    "    # Compute WER\n",
    "    error = compute_wer(sample[\"reference\"], prediction)\n",
    "    wers.append(error)\n",
    "    refs_preds.append((sample[\"reference\"], prediction, error))\n",
    "\n",
    "# calculate average WER and print results\n",
    "average_wer = sum(wers) / len(wers)\n",
    "print(f\"Average WER: {average_wer:.2%}\")\n",
    "\n",
    "# show a few random samples\n",
    "\n",
    "for ref, pred, err in random.sample(refs_preds, min(5, len(refs_preds))):\n",
    "    print(f\"Reference: {ref}\")\n",
    "    print(f\"Predicted: {pred}\")\n",
    "    print(f\"WER: {err:.2%}\\n\")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(fp, map_location=device)\n",
      "100%|██████████| 934/934 [1:00:08<00:00,  3.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average WER: 95.69%\n",
      "Reference: doduerch ass se ofwäertskompabitel mat 802.11a 802.11b an 802.11g virausgesat datt d'basisstatioun iwwer zwee funkapparater verfüügt\n",
      "Predicted: Dadurch ist also aufwärtskompatibel mit Etonaut 2,11a, Etonaut 2,11b und Etonaut 2,11g herausgesagt, dass Basis Station IWA 2 von dem Operator verfügt.\n",
      "WER: 110.00%\n",
      "\n",
      "Reference: d'mënsche schreiwen elo noriichten op computerbildschiermer a brauche kee spëtzer méi\n",
      "Predicted: Mnče škravno ljudno rešeno kompiutabil šema, a brak kajn špacomej.\n",
      "WER: 91.67%\n",
      "\n",
      "Reference: d'haaptstad vu moldawien ass chişinău. d'landessprooch ass rumänesch awer russesch ass wäit verbreet\n",
      "Predicted: Die Hauptstadt von Moldawien ist Chisinau. Die Landessprache ist Rumänisch, aber Russisch ist weit verbreitet.\n",
      "WER: 93.33%\n",
      "\n",
      "Reference: virtuell gerüster sinn an der software verënnerlecht a solle verfaren hannerfroen opfuerderen an erklären déi fir de schüler ze schwiereg gewiescht kéinte sinn se eleng ze bewältegen\n",
      "Predicted: ושתו אל גרויסטה זינן דה סופטוייפה ענאלה שט, עזולה פרפהרן ענה פרוון, עקפודרן, ענה קלערן, דה פי את שילה צה שבירש גביר שכנת איזן זו צה אל אינג צה בוולטג'ן.\n",
      "WER: 114.81%\n",
      "\n",
      "Reference: normalerweis héiert dir ëmmer de kaméidi vun touristen an händler d'geschicht vu klang a liicht ass ewéi e märerchersbuch\n",
      "Predicted: Ja dan organizu\n",
      "WER: 100.00%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = whisper.load_model(\"medium\")\n",
    "refs_preds = []\n",
    "wers = []\n",
    "\n",
    "for sample in tqdm(prepared_samples):\n",
    "    # Transcribe the audio\n",
    "    result = model.transcribe(sample[\"path\"], task=\"transcribe\")\n",
    "    prediction = result[\"text\"].strip()\n",
    "\n",
    "    # Compute WER\n",
    "    error = compute_wer(sample[\"reference\"], prediction)\n",
    "    wers.append(error)\n",
    "    refs_preds.append((sample[\"reference\"], prediction, error))\n",
    "\n",
    "# calculate average WER and print results\n",
    "average_wer = sum(wers) / len(wers)\n",
    "print(f\"Average WER: {average_wer:.2%}\")\n",
    "\n",
    "# show a few random samples\n",
    "\n",
    "for ref, pred, err in random.sample(refs_preds, min(5, len(refs_preds))):\n",
    "    print(f\"Reference: {ref}\")\n",
    "    print(f\"Predicted: {pred}\")\n",
    "    print(f\"WER: {err:.2%}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at Lemswasabi/wav2vec2-base-luxembourgish-4h were not used when initializing Wav2Vec2ForCTC: ['wav2vec2.encoder.pos_conv_embed.conv.weight_g', 'wav2vec2.encoder.pos_conv_embed.conv.weight_v']\n",
      "- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at Lemswasabi/wav2vec2-base-luxembourgish-4h and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 934/934 [00:26<00:00, 34.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average WER: 62.36%\n",
      "Reference: de 15 august 1940 sinn d'alliéierter a südfrankräich agefall d'invasioun gouf operation dragoon genannt\n",
      "Predicted: de aurgust sin ea liéierten a süd frankräich agefal dim vasioun gouf op peration dra gon genant\n",
      "WER: 100.00%\n",
      "\n",
      "Reference: d'höl läit op engem bierg nërdlech vu mekka an ass komplett vum rescht vun der welt isoléiert\n",
      "Predicted: toul läit op engem bierg nartlech vum macker an as komplet vum recht vun der welt isoléiert\n",
      "WER: 44.44%\n",
      "\n",
      "Reference: onnéideg ze soen wann dir eng romanesch sprooch kennt gëtt et méi einfach portugisesch ze léieren\n",
      "Predicted: onéidegh ze soen wan dir eng homanesch sprochkënt gët et méi einfach portugisesch zu dieren\n",
      "WER: 50.00%\n",
      "\n",
      "Reference: dës koppele kënne sech entscheeden en adoptiounsplang fir hire puppelchen ze maachen\n",
      "Predicted: dës copeleu këne sech entscheden a at optionsplang fir re popochen ze machen\n",
      "WER: 75.00%\n",
      "\n",
      "Reference: zu de regionalen a saisonalen onwiederphenomeener gehéiere blizzarden schnéistierm äisstierm a stëbsstierm\n",
      "Predicted: zu de regionalen as seisonalen onvider phänomen gehéiere blisaden schnéischtierm äishtierm a stëpstienm\n",
      "WER: 66.67%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Setup device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load model and processor\n",
    "model_name = \"Lemswasabi/wav2vec2-base-luxembourgish-4h\"\n",
    "processor = Wav2Vec2Processor.from_pretrained(model_name)\n",
    "model = Wav2Vec2ForCTC.from_pretrained(model_name).to(device).eval()\n",
    "\n",
    "# Store results\n",
    "refs_preds = []\n",
    "wers = []\n",
    "\n",
    "# Evaluate\n",
    "for sample in tqdm(prepared_samples):\n",
    "    # Load resampled audio from disk\n",
    "    speech_array, _ = sf.read(sample[\"path\"])  # already 16kHz from preprocessing\n",
    "\n",
    "    # Tokenize\n",
    "    inputs = processor(speech_array, sampling_rate=16000, return_tensors=\"pt\", padding=True)\n",
    "    input_values = inputs.input_values.to(device)\n",
    "    attention_mask = inputs.attention_mask.to(device) if \"attention_mask\" in inputs else None\n",
    "\n",
    "    # Inference\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_values, attention_mask=attention_mask).logits \\\n",
    "            if attention_mask is not None else model(input_values).logits\n",
    "\n",
    "    predicted_ids = torch.argmax(logits, dim=-1)\n",
    "    transcription = processor.decode(predicted_ids[0], skip_special_tokens=True).strip()\n",
    "\n",
    "    # Compute WER\n",
    "    reference = sample[\"reference\"]\n",
    "    error = compute_wer(reference, transcription)\n",
    "\n",
    "    wers.append(error)\n",
    "    refs_preds.append((reference, transcription, error))\n",
    "\n",
    "# calculate average WER and print results\n",
    "average_wer = sum(wers) / len(wers)\n",
    "print(f\"Average WER: {average_wer:.2%}\")\n",
    "\n",
    "# show a few random samples\n",
    "\n",
    "for ref, pred, err in random.sample(refs_preds, min(5, len(refs_preds))):\n",
    "    print(f\"Reference: {ref}\")\n",
    "    print(f\"Predicted: {pred}\")\n",
    "    print(f\"WER: {err:.2%}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Evaluating Tun-Wellens/pgilles-whisper-tiny-lb\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a88daee46dc54fc681c3d430e7aed948",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.31k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91c711ab87f84af981ffcf03e71c18a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/151M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5894d8d9c824f56926dc6a1149b4671",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/3.74k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "004adc7ebce840e28b55674502ddb317",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/283k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94de2dd1154447c4b366b858dd5c63a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6857d9e3d857425e8267bb26e1204e36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/494k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12621fa30e1843478de71e0b5a51e275",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "normalizer.json:   0%|          | 0.00/52.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61c923182e0e4f34b09a4f757391b64c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/34.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f8f2288af6a42afa28aa265f27e039a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/2.19k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e2a453731424f98a4eb48a67f470187",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/339 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Whisper Eval: Tun-Wellens/pgilles-whisper-tiny-lb:   0%|          | 0/934 [00:00<?, ?it/s]Due to a bug fix in https://github.com/huggingface/transformers/pull/28687 transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English.This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`.\n",
      "Whisper Eval: Tun-Wellens/pgilles-whisper-tiny-lb:   1%|          | 10/934 [00:02<03:20,  4.61it/s]You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "Whisper Eval: Tun-Wellens/pgilles-whisper-tiny-lb: 100%|██████████| 934/934 [04:02<00:00,  3.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Average WER (Tun-Wellens/pgilles-whisper-tiny-lb) over 934 valid samples: 80.17%\n",
      "\n",
      " Sample predictions (Tun-Wellens/pgilles-whisper-tiny-lb):\n",
      "\n",
      "Reference: no der revolutioun waren aarbechtsplaze fir all männlech bewerber op wat et den éiergäizegsten a erfollegräichsten erméiglecht huet et ze packen\n",
      "Predicted: No der Revolutioun war en Aarbechtsplaz fir handlännesch Bewerb op, wat et den éiergäizegsten an erfollegräistener Méiglechthescht huet, an ze packen.\n",
      "WER: 47.62%\n",
      "\n",
      "Reference: wat d'spannung méi niddereg wat d'existent liewenskraaft méi positiv jiddwer mënsch huet d'potenzial absolutte fridden an zefriddenheet ze fannen\n",
      "Predicted: Wat Spannung meng Niddere schafen, déi sech dann sech déi gesinn d' Liewenskraaft méi positiv jiddere Mënsch huet, datt sech sel op zesumme Fridden anzefidden net ze fannen.\n",
      "WER: 86.36%\n",
      "\n",
      "Reference: dem aristoteles seng usiichte goufen an alle beräicher vun der wëssenschaft akzeptéiert inklusiv der psychologie\n",
      "Predicted: De Marie-Soudle seng u sech dee goufen an alle Beräicher vun der wëssescher Exaktéiert, déi inklusiv der Psychologie.\n",
      "WER: 60.00%\n",
      "\n",
      "Reference: paräiser hunn de ruff egozentresch onhéiflech an arrogant ze sinn\n",
      "Predicted: Jee Paräisser hunn der Ruff, hir gezännteres, onhéiflech an aneren.\n",
      "WER: 80.00%\n",
      "\n",
      "Reference: dat sinn heiansdo iwwerfëllt familljestränn mat enger gudder auswiel u butteker laanscht d'küst schwammen ass sécher\n",
      "Predicted: Et ass eng neien Souverre vëllverwiicht dräi mat enger gudder Auswierl uebut déi ganänscht Kriiseschwammen ass sécher.\n",
      "WER: 82.35%\n",
      "\n",
      "\n",
      " Evaluating Tun-Wellens/pgilles-whisper-medium-lb\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "326d6ad6f5884242ae204c717f8f0d0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.03k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c5f5666a43f4742a22a9e5fd2f075fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/3.06G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d54bcc525a74068b9b2f53095c92d8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/3.46k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88648e07be09442788ca22ef49b0ff16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/787 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8725822f335849c3a8eccd857c40d955",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22c1da2cedfc40a0b097ba4f4b6e1aed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/494k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9eead3c6ced4c3686e30127e88525e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "normalizer.json:   0%|          | 0.00/52.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0b0ac54ef4f4a5da88e8c0534c61bfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/2.11k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e68452fdfee419d9016d947e73809e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/2.06k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9237626b30c4e8f920c5f83d506a2fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/185k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Whisper Eval: Tun-Wellens/pgilles-whisper-medium-lb: 100%|██████████| 934/934 [18:03<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Average WER (Tun-Wellens/pgilles-whisper-medium-lb) over 934 valid samples: 49.79%\n",
      "\n",
      " Sample predictions (Tun-Wellens/pgilles-whisper-medium-lb):\n",
      "\n",
      "Reference: genee esou musst dir mat engem schengen-visa net fir jiddwer schenge-memberstat separat e visa ufroen wat zäit suen a schreifaarbecht erspuert\n",
      "Predicted: Den hir sou muss du mat engem Schengem Visa net fir jidde wa Schengem Memberstad, separat de Visa ufruen, verzäit Suen a schreiwaarbeje schwuet.\n",
      "WER: 69.57%\n",
      "\n",
      "Reference: schinneschwelle goufen zimmlech fréi ageféiert fir d'schinnen op der plaz ze halen no an no huet sech awer erausgestallt datt d'schinne méi effizient wieren wa se en eisestaf uewen hätten\n",
      "Predicted: Schinnen e schwelle goufen zimlech fräi ageféiert fir d'Schinnen op de Plaz ze halen. No an no huet se sech awer erausgestallt datt d'Schinnen er méi effizient wieren, wa se een eise Staf uewen hätten.\n",
      "WER: 37.50%\n",
      "\n",
      "Reference: mierkt iech och wann d'musek op den haaptbüne dem enn zou geet kann et nach beräicher vum festival ginn déi bis spéit an d'nuecht musek spillen\n",
      "Predicted: Mierk d'Iech, of wann d'Musik op den Haaptbunnenen zum Hän zougeet, kann et nach Beräicher vum Festival ginn, déi bispéin an d'Nuecht musik spillen.\n",
      "WER: 42.86%\n",
      "\n",
      "Reference: d'krankheet gëtt vu schwäin iwwerdroen déi dann iwwer mustiken op de mënsch iwwergeet\n",
      "Predicted: D'Krankheet gëtt vu Schwäini iwwer druen, déi dann iwwer Mustiken op de Mënsch iwwegitt.\n",
      "WER: 28.57%\n",
      "\n",
      "Reference: d'stad ass och den ausgangspunkt fir op den nyiragongo-vulkan ze klammen an och fir e puer vun de bëllegste bierggorillaausflich an afrika\n",
      "Predicted: Ech hat ee sot den Auskonspunkt fir op den Nieragongo Vulkan ze klammen an och fir e puer vun de bëllegste Bierg, Gorilla, Auschwitz an Afrika.\n",
      "WER: 37.50%\n",
      "\n",
      "\n",
      " Evaluating Tun-Wellens/pgilles-whisper-large-lb\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1642128af3204a27b768dac7573bdbc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.03k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c4f5ea2d27c461b996a6d77da52f003",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/6.17G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2f64c2de83f4345bca7fe5a85d957fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/3.56k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f78cd884c39347d4ad43ac285bcbec10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/787 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfe6ce2a11dd4f109272d4195281c075",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f455f07d441c45c6a987a9e64dea9ff1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/494k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1340b868e0454c628059f265bcae378c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "normalizer.json:   0%|          | 0.00/52.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fe9a01cb0f144b390faaf9059c985f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/2.11k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5116a388b0a491c912efcf7007e9b2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/2.06k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c741774a6964b23aff77cec2d5c86f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/185k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Whisper Eval: Tun-Wellens/pgilles-whisper-large-lb: 100%|██████████| 934/934 [26:09<00:00,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Average WER (Tun-Wellens/pgilles-whisper-large-lb) over 934 valid samples: 57.97%\n",
      "\n",
      " Sample predictions (Tun-Wellens/pgilles-whisper-large-lb):\n",
      "\n",
      "Reference: et kann ee sech nëmme froen wat mat der tastatur geschitt wann eppes méi neits kënnt\n",
      "Predicted: Et kann ee sech nëmme froen, wat mat der Tastatur geschitt, wann eppes Neits gëtt.\n",
      "WER: 12.50%\n",
      "\n",
      "Reference: den ofstuerz huet sech héich uewen a biergegem terrain ereegent an et gëtt ugeholl datt et d'resultat vu feindlechem beschoss war\n",
      "Predicted: Den Ofstuert huet sech héich uewen a biergergem Terrain eréignert an et gëtt ugeholl, datt et d'Resultat vu feindleche Beschoss war.\n",
      "WER: 18.18%\n",
      "\n",
      "Reference: déi dräi kinnekräicher war ee vun den bluddegsten zäitalteren am ale china dausende mënsche si beim kampf ëm den héchste sëtz am grousse palais zu xi'an gestuerwen\n",
      "Predicted: Déi dräi Kinnekräicher waren ee vun de bluddegsten Zäitalteren an aller China. Dausende Mënsche si beim Kampf ëm den héckschte Sëtz an de grousse Palette z'Uxiane gestuerwen.\n",
      "WER: 39.29%\n",
      "\n",
      "Reference: den giancarlo fisichella huet d'kontroll iwwer säin auto verluer an d'course ganz kuerz nom start bëendegt\n",
      "Predicted: Den Gian Carlo Fischieller huet d'Kontroll iwwer seng Auto verluer an d'Kurz kënnt seng Kéier op d'Stach geännegt ginn.\n",
      "WER: 72.22%\n",
      "\n",
      "Reference: d'wëssenschaftler konnte schlussfollgeren datt d'donkel materie aner donkel materie op déi selwecht weis beaflosst ewéi normal materie\n",
      "Predicted: D'Wëssenschaftler konnte Schlussfolgeren, datt dunkel Materie aner dunkel Materie op déi selwecht weistbar Aflost ewéi normal Materie.\n",
      "WER: 31.58%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# List of pgilles Whisper models fine-tuned on Luxembourgish\n",
    "whisper_models = [\n",
    "    \"Tun-Wellens/pgilles-whisper-tiny-lb\",\n",
    "    \"Tun-Wellens/pgilles-whisper-medium-lb\",\n",
    "    \"Tun-Wellens/pgilles-whisper-large-lb\",\n",
    "]\n",
    "\n",
    "for whisper_model_name in whisper_models:\n",
    "    print(f\"\\n Evaluating {whisper_model_name}\")\n",
    "\n",
    "    asr = pipeline(\n",
    "        \"automatic-speech-recognition\",\n",
    "        model=whisper_model_name,\n",
    "        device=0 if torch.cuda.is_available() else -1\n",
    "    )\n",
    "\n",
    "    refs_preds = []\n",
    "    wers = []\n",
    "    skipped = 0\n",
    "\n",
    "    for sample in tqdm(prepared_samples, desc=f\"Whisper Eval: {whisper_model_name}\"):\n",
    "        try:\n",
    "            # Load already-preprocessed 16kHz audio from file\n",
    "            speech_array, _ = sf.read(sample[\"path\"])\n",
    "\n",
    "            # Run transcription\n",
    "            result = asr(\n",
    "                {\"array\": speech_array, \"sampling_rate\": 16000}\n",
    "            )\n",
    "            transcription = result[\"text\"].strip()\n",
    "\n",
    "            # Compute WER\n",
    "            reference = sample[\"reference\"]\n",
    "            error = compute_wer(reference, transcription)\n",
    "\n",
    "            wers.append(error)\n",
    "            refs_preds.append((reference, transcription, error))\n",
    "\n",
    "        except ValueError as e:\n",
    "            if \"more than 3000 mel input features\" in str(e):\n",
    "                skipped += 1\n",
    "                continue\n",
    "            else:\n",
    "                raise e  # re-raise unexpected errors\n",
    "\n",
    "    # Average WER\n",
    "    if wers:\n",
    "        average_wer_pgilles = sum(wers) / len(wers)\n",
    "        print(f\"\\n Average WER ({whisper_model_name}) over {len(wers)} valid samples: {average_wer_pgilles:.2%}\")\n",
    "    else:\n",
    "        print(f\"\\n No valid samples for {whisper_model_name}\")\n",
    "\n",
    "    if skipped:\n",
    "        print(f\" Skipped {skipped} sample(s) due to long-form constraint (>30s)\")\n",
    "\n",
    "    # Show sample predictions\n",
    "    if refs_preds:\n",
    "        print(f\"\\n Sample predictions ({whisper_model_name}):\\n\")\n",
    "        for ref, pred, err in random.sample(refs_preds, min(5, len(refs_preds))):\n",
    "            print(f\"Reference: {ref}\")\n",
    "            print(f\"Predicted: {pred}\")\n",
    "            print(f\"WER: {err:.2%}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 934/934 [35:24<00:00,  2.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Average WER (LuxASR) over 934 samples: 23.48%\n",
      "\n",
      " Sample predictions (LuxASR):\n",
      "\n",
      "Reference: d'zentral autoritéit vun der kierch war zanter iwwer dausend joer zu roum an dës konzentratioun vu muecht a suen huet der vill dozou bruecht dorun ze zweiwelen ob dëse grondsaz erfëllt gouf\n",
      "Predicted: D'zentral Autoritéit vun der Kierch war zanter iwwer dausend Joer zu Rou, an dës Konzentratioun vu Muecht a Suen huet der vill dozou bruecht, dorun ze zweifelen, ob dësem Grondsätz erfëllt gouf.\n",
      "WER: 12.12%\n",
      "\n",
      "Reference: de scotturb bus 403 fiert reegelméisseg op sintra a bleift a cabo da roca stoen\n",
      "Predicted: De Scott-E-Bus véierhonnertdräi féiert reegelméisseg op Sintra a bleift a Cabuda Roca stoen.\n",
      "WER: 40.00%\n",
      "\n",
      "Reference: esou ewéi de mound eng unzéiungskraaft op d'äerd ausüübt a gezäite verursaacht esou üübt d'mëllechstrooss eng kraaft op d'sagittarius-galaxie aus\n",
      "Predicted: Esou wéi de Mound eng Unzéiungskraaft op d'Äert ausüübt a Gezäite verursacht, esou üübt d'Mëllechstrooss eng Kraaft op der Pythariusgalaxie aus.\n",
      "WER: 25.00%\n",
      "\n",
      "Reference: nuets goufen tëschent 150 bis 200 kopië gemaach déi haut als dunlap broadsides bekannt sinn\n",
      "Predicted: Nuets goufen zwëschent eenthonnertfofzeg bis zweehonnert Kopiën gemaach, déi haut als Dunlap Broutside bekannt sinn.\n",
      "WER: 33.33%\n",
      "\n",
      "Reference: am norde musst dir och de bedeitenden hellegtum vu der fátima schräin besichen eng weltwäit bekannt plaz fir marienerscheinungen\n",
      "Predicted: Am Norde muss ee och de bedeitenden Helleschttum vun der Fatima Schreie besichen, eng weltwäert bekannt Plaz fir Marienerscheinung.\n",
      "WER: 42.11%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# LuxASR endpoint\n",
    "LUXASR_API = \"https://luxasr.uni.lu/v2/asr?diarization=Disabled&outfmt=text\"\n",
    "\n",
    "refs_preds = []\n",
    "wers = []\n",
    "\n",
    "for sample in tqdm(prepared_samples):\n",
    "    with open(sample[\"path\"], \"rb\") as audio_file:\n",
    "        files = {\"audio_file\": (\"audio.wav\", audio_file, \"audio/wav\")}\n",
    "        response = requests.post(LUXASR_API, files=files, timeout=30)\n",
    "        predicted = json.loads(response.text.strip())\n",
    "\n",
    "    # Compute WER\n",
    "    error = compute_wer(sample[\"reference\"], predicted)\n",
    "    wers.append(error)\n",
    "    refs_preds.append((sample[\"reference\"], predicted, error))\n",
    "\n",
    "    time.sleep(1)  \n",
    "\n",
    "# Average WER\n",
    "average_wer = sum(wers) / len(wers)\n",
    "print(f\"\\n Average WER (LuxASR) over {len(wers)} samples: {average_wer:.2%}\")\n",
    "\n",
    "# Show sample predictions\n",
    "print(\"\\n Sample predictions (LuxASR):\\n\")\n",
    "for ref, pred, err in random.sample(refs_preds, min(5, len(refs_preds))):\n",
    "    print(f\"Reference: {ref}\")\n",
    "    print(f\"Predicted: {pred}\")\n",
    "    print(f\"WER: {err:.2%}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
